from aiida import orm
from aiida.common.links import LinkType
from aiida.engine import ProcessState
from enum import Enum
from collections import OrderedDict
from abc import ABC, abstractmethod
from pathlib import Path
from ..workchains import clean_workdir
from aiida.tools import delete_nodes

class BaseWorkChainAnalyser(ABC):
    """
    BaseAnalyser for the WorkChain.
    """


    def __init__(self, workchain: orm.WorkChainNode):
        self.node = workchain
        self.descendants = {}

    @staticmethod
    @abstractmethod
    def base_check(
        workchain: orm.WorkChainNode,
        excepted_state,
        failed_state,
        killed_state,
        finished_ok_state,
        namespace: str,
        ):
        pass

    @staticmethod
    def get_calcjob_paths(processes_dict, parent_label=''):
        """
        Recursively extract all CalcJob remote paths from the nested dictionary created by get_processes_dict.

        :param processes_dict: The dictionary generated by get_processes_dict.
        :param parent_label: The parent path for building hierarchical labels (used internally for recursion).
        :return: A flattened dictionary { 'full label': 'remote path' }.
        """
        flat_paths = {}
        for label, sub_dict in processes_dict.items():
            if not isinstance(sub_dict, dict):
                continue
            full_label = f"{parent_label}/{label}" if parent_label else label

            if 'calcjob_node' in sub_dict:
                calcjob = sub_dict['calcjob_node']
                remote_path = calcjob.outputs.remote_folder.get_remote_path()
                flat_paths[full_label] = remote_path

            if 'workchain_node' in sub_dict:
                # Pass the current workchain's subprocess dictionary and the new parent label
                nested_paths = BaseWorkChainAnalyser.get_calcjob_paths(
                    sub_dict,
                    parent_label=full_label
                )
                flat_paths.update(nested_paths)

        return flat_paths

    # TODO: For link_labels with multiple workchains, the processes_dict will be problematic.
    #       We need to fix this.
    @staticmethod
    def get_processes_dict(node):
        """Get the remote directory of the all workchains."""
        processes_dict = {}
        for subprocess in node.called:
            if 'CalcJobNode' in subprocess.node_type:
                link_label = subprocess.base.attributes.all['metadata_inputs']['metadata']['call_link_label']
                processes_dict[link_label] = {'calcjob_node': subprocess}

            elif 'WorkChainNode' in subprocess.node_type:
                link_label = subprocess.base.attributes.all['metadata_inputs']['metadata']['call_link_label']
                processes_dict[link_label] = {'workchain_node': subprocess}
                sub_paths = BaseWorkChainAnalyser.get_processes_dict(subprocess)
                processes_dict[link_label].update(sub_paths)
            else:
                pass

        return processes_dict


    @staticmethod
    def get_retrieved(node):
        """Get the retrieved of the all workchains."""
        retrieved = {}

        for subprocess in node.called:
            if 'CalcJobNode' in subprocess.node_type:
                link_label = subprocess.base.attributes.all['metadata_inputs']['metadata']['call_link_label']
                retrieved[link_label] = subprocess.outputs.retrieved if subprocess.outputs.retrieved else None

            elif 'WorkChainNode' in subprocess.node_type:
                link_label = subprocess.base.attributes.all['metadata_inputs']['metadata']['call_link_label']
                retrieved[link_label] = {}
                sub_paths = BaseWorkChainAnalyser.get_retrieved(subprocess)
                retrieved[link_label].update(sub_paths)
            else:
                pass
        return retrieved

    @staticmethod
    def _dump_inputs(processes_dict, destpath: Path):

        for label, sub_dict in processes_dict.items():
            if not isinstance(sub_dict, dict):
                continue
            full_label = destpath / label

            if 'calcjob_node' in sub_dict:
                calcjob = sub_dict['calcjob_node']
                destpath.mkdir(parents=True, exist_ok=True)

                for filename in ['aiida.in', 'aiida.win']:
                    try:
                        with open(destpath / filename, 'w') as f:
                            f.write(calcjob.base.repository.get_object_content(filename))
                    except FileNotFoundError:
                        continue
                try:
                    for filename in calcjob.outputs.retrieved.list_object_names('DYN_MAT'):
                        DYN_MAT = destpath / 'DYN_MAT'
                        DYN_MAT.mkdir(parents=True, exist_ok=True)
                        with open(DYN_MAT / filename, 'w') as f:
                            f.write(calcjob.outputs.retrieved.get_object_content(f"DYN_MAT/{filename}"))
                except FileNotFoundError:
                    continue

                for filename in ['aiida.out', 'aiida.fc' 'phonon_frequencies.dat', 'phonon_displacements.dat']:
                    try:
                        with open(destpath / filename, 'w') as f:
                            f.write(calcjob.outputs.retrieved.get_object_content(filename))
                    except FileNotFoundError:
                        continue

            if 'workchain_node' in sub_dict:
                # Pass the current workchain's subprocess dictionary and the new parent label
                BaseWorkChainAnalyser._dump_inputs(
                    sub_dict,
                    destpath=full_label
                )

    @abstractmethod
    def dump_inputs(self, destpath: Path):
        pass

    @abstractmethod
    def get_state(self):
        pass

    @abstractmethod
    def get_source(self):
        pass

    @staticmethod
    def get_descendants_by_label(
        workchain: orm.WorkChainNode,
        link_label_filter: str
        ) -> orm.WorkChainNode:
        """Get the descendant workchains of the parent workchain by the link label."""
        try:
            return workchain.base.links.get_outgoing(
                link_label_filter=link_label_filter
                ).all()
        except AttributeError:
            return None

    @abstractmethod
    def clean_workchain(self, exempted_states, dry_run=True):
        """Clean the workchain."""

        state, _ = self.check_process_state()
        message = ''
        if state in exempted_states:
            message += 'Please check if you really want to clean this workchain.'
            return message

        cleaned_calcs = clean_workdir(self.node, dry_run=dry_run)
        message += f'Cleaned the workchain {self.node.pk}:\n'
        message += '  ' + ' '.join(map(str, cleaned_calcs)) + '\n'
        message += f'Deleted the workchain {self.node.pk}:\n'
        deleted_nodes, _ = delete_nodes([self.node.pk], dry_run=dry_run)
        message += '  ' + ' '.join(map(str, deleted_nodes))

        return message